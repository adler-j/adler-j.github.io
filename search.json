[
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1541289600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1541289600,
    "objectID": "35168d9127408975729cfd24b18f2fbe",
    "permalink": "http://jonasadler.com/talk/2018unibath/",
    "publishdate": "2018-11-04T00:00:00Z",
    "relpermalink": "/talk/2018unibath/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: Data-driven optimization",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1539903600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1539903600,
    "objectID": "d45fb75c51af6505f06cd754a93eb8bc",
    "permalink": "http://jonasadler.com/talk/2018icmsec/",
    "publishdate": "2018-10-19T00:00:00+01:00",
    "relpermalink": "/talk/2018icmsec/",
    "section": "talk",
    "summary": "Deep learning has shown tremendous success in solving various tasks in several fields of science such as in image and natural language processing. Recently, it has also been applied to solve inverse problems and empirical evidence in image reconstruction points to exponential improvements in both performance and run-time over classical approaches. In this talk we outline some of these recent developments.\nIn particular, we'll introduce 'Learned Iterative Reconstruction', a method which relies on a fusion of model- and data-driven approaches for solving inverse problems.\nWe'll also show how these methods can be extended to 'Deep Bayesian Inversion', a family of methods that allows us to perform uncertainty quantification using deep learning.",
    "tags": [],
    "title": "Invited talk: Deep Learning for Image Reconstruction",
    "type": "talk"
  },
  {
    "authors": [
      "Jonas Adler",
      "Sebastian Lunz",
      "Olivier Verdier",
      "Carola-Bibiane Schönlieb",
      "Ozan Öktem"
    ],
    "categories": null,
    "content": "",
    "date": 1535324400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1535324400,
    "objectID": "6ab05ad9760cd25c5163cda9bd26d281",
    "permalink": "http://jonasadler.com/publication/task_adapted_recon/",
    "publishdate": "2018-08-27T00:00:00+01:00",
    "relpermalink": "/publication/task_adapted_recon/",
    "section": "publication",
    "summary": "The paper considers the problem of performing a task defined on a model parameter that is only observed indirectly through noisy data in an ill-posed inverse problem. A key aspect is to formalize the steps of reconstruction and task as appropriate estimators (non-randomized decision rules) in statistical estimation problems. The implementation makes use of (deep) neural networks to provide a differentiable parametrization of the family of estimators for both steps. These networks are combined and jointly trained against suitable supervised training data in order to minimize a joint differentiable loss function, resulting in an end-to-end task adapted reconstruction method. The suggested framework is generic, yet adaptable, with a plug-and-play structure for adjusting both the inverse problem and the task at hand. More precisely, the data model (forward operator and statistical model of the noise) associated with the inverse problem is exchangeable, eg, by using neural network architecture given by a learned iterative method. Furthermore, any task that is encodable as a trainable neural network can be used. The approach is demonstrated on joint tomographic image reconstruction, classification and joint tomographic image reconstruction segmentation.",
    "tags": [],
    "title": "Task adapted reconstruction for inverse problems",
    "type": "publication"
  },
  {
    "authors": [
      "Nikita Moriakov",
      "Koen Michielsen",
      "Jonas Adler",
      "Ritse Mann",
      "Ioannis Sechopoulos",
      "Jonas Teuwen"
    ],
    "categories": null,
    "content": "",
    "date": 1534201200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1534201200,
    "objectID": "e42981e8129deee1f4132dbe48758e19",
    "permalink": "http://jonasadler.com/publication/deep_learning_digital_breast_tomosynthesis/",
    "publishdate": "2018-08-14T00:00:00+01:00",
    "relpermalink": "/publication/deep_learning_digital_breast_tomosynthesis/",
    "section": "publication",
    "summary": "Digital breast tomosynthesis is rapidly replacing digital mammography as the basic x-ray technique for evaluation of the breasts. However, the sparse sampling and limited angular range gives rise to different artifacts, which manufacturers try to solve in several ways. In this study we propose an extension of the Learned Primal-Dual algorithm for digital breast tomosynthesis. The Learned Primal-Dual algorithm is a deep neural network consisting of several `reconstruction blocks', which take in raw sinogram data as the initial input, perform a forward and a backward pass by taking projections and back-projections, and use a convolutional neural network to produce an intermediate reconstruction result which is then improved further by the successive reconstruction block. We extend the architecture by providing breast thickness measurements as a mask to the neural network and allow it to learn how to use this thickness mask. We have trained the algorithm on digital phantoms and the corresponding noise-free/noisy projections, and then tested the algorithm on digital phantoms for varying level of noise. Reconstruction performance of the algorithms was compared visually, using MSE loss and Structural Similarity Index. Results indicate that the proposed algorithm outperforms the baseline iterative reconstruction algorithm in terms of reconstruction quality for both breast edges and internal structures and is robust to noise.",
    "tags": [],
    "title": "Deep Learning Framework for Digital Breast Tomosynthesis Reconstruction",
    "type": "publication"
  },
  {
    "authors": [
      "Sebastian Banert",
      "Axel Ringh",
      "Jonas Adler",
      "Johan Karlsson",
      "Ozan Öktem"
    ],
    "categories": null,
    "content": "",
    "date": 1533164400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1533164400,
    "objectID": "e188a05e68c0b74e14e066110f4efa43",
    "permalink": "http://jonasadler.com/publication/data_driven_nonsmooth_optimization/",
    "publishdate": "2018-08-02T00:00:00+01:00",
    "relpermalink": "/publication/data_driven_nonsmooth_optimization/",
    "section": "publication",
    "summary": "In this work, we consider methods for solving large-scale optimization problems with a possibly nonsmooth objective function. The key idea is to first specify a class of optimization algorithms using a generic iterative scheme involving only linear operations and applications of proximal operators. This scheme contains many modern primal-dual first-order solvers like the Douglas-Rachford and hybrid gradient methods as special cases. Moreover, we show convergence to an optimal point for a new method which also belongs to this class. Next, we interpret the generic scheme as a neural network and use unsupervised training to learn the best set of parameters for a specific class of objective functions while imposing a fixed number of iterations. In contrast to other approaches of 'learning to optimize', we present an approach which learns parameters only in the set of convergent schemes. As use cases, we consider optimization problems arising in tomographic reconstruction and image deconvolution, and in particular a family of total variation regularization problems.",
    "tags": [],
    "title": "Data-driven Nonsmooth Optimization",
    "type": "publication"
  },
  {
    "authors": [
      "Zhichao  Zhong",
      "Willem Jan Palenstijn",
      "Jonas Adler",
      "K. Joost Batenburg"
    ],
    "categories": null,
    "content": "",
    "date": 1533078000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1533078000,
    "objectID": "8dccbae0da8aac92e478d98756e71528",
    "permalink": "http://jonasadler.com/publication/eds_tomo_recon/",
    "publishdate": "2018-08-01T00:00:00+01:00",
    "relpermalink": "/publication/eds_tomo_recon/",
    "section": "publication",
    "summary": "Energy-dispersive X-ray spectroscopy (EDS) tomography is an advanced technique to characterize compositional information for nanostructures in three dimensions (3D). However, the application is hindered by the poor image quality caused by the low signal-to-noise ratios and the limited number of tilts, which are fundamentally limited by the insufficient number of X-ray counts. In this paper, we explore how to make accurate EDS reconstructions from such data. We propose to augment EDS tomography by joining with it a more accurate high-angle annular dark-field STEM (HAADF-STEM) tomographic reconstruction, for which usually a larger number of tilt images are feasible. This augmentation is realized through total nuclear variation (TNV) regularization, which encourages the joint EDS and HAADF reconstructions to have not only sparse gradients but also common edges and parallel (or antiparallel) gradients. Our experiments show that reconstruction images are more accurate compared to the non-regularized and the total variation regularized reconstructions, even when the number of tilts is small or the X-ray counts are low.",
    "tags": [],
    "title": "EDS tomographic reconstruction regularized by total nuclear variation joined with HAADF-STEM tomography",
    "type": "publication"
  },
  {
    "authors": [
      "Jonas Adler",
      "Sebastian Lunz"
    ],
    "categories": null,
    "content": "",
    "date": 1529276400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1529276400,
    "objectID": "667d5bc8019feb8b9a074c2bd720258f",
    "permalink": "http://jonasadler.com/publication/bwgan/",
    "publishdate": "2018-06-18T00:00:00+01:00",
    "relpermalink": "/publication/bwgan/",
    "section": "publication",
    "summary": "Wasserstein Generative Adversarial Networks (WGANs) can be used to generate realistic samples from complicated image distributions. The Wasserstein metric used in WGANs is based on a notion of distance between individual images, which induces a notion of distance between probability distributions of images. So far the community has considered ℓ2 as the underlying distance. We generalize the theory of WGAN with gradient penalty to Banach spaces, allowing practitioners to select the features to emphasize in the generator. We further discuss the effect of some particular choices of underlying norms, focusing on Sobolev norms. Finally, we demonstrate the impact of the choice of norm on model performance and show state-of-the-art inception scores for non-progressive growing GANs on CIFAR-10.",
    "tags": [],
    "title": "Banach Wasserstein GAN",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1528412400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1528412400,
    "objectID": "5edc2b633754d60aba0b84a135192d4a",
    "permalink": "http://jonasadler.com/talk/2018siam_ct/",
    "publishdate": "2018-06-08T00:00:00+01:00",
    "relpermalink": "/talk/2018siam_ct/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: Learned Iterative Reconstruction for CT",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1528412400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1528412400,
    "objectID": "f6dbfd5c14dd4e13e74f73f53a0043f4",
    "permalink": "http://jonasadler.com/talk/2018siam_odl/",
    "publishdate": "2018-06-08T00:00:00+01:00",
    "relpermalink": "/talk/2018siam_odl/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: Learning to solve inverse problems with ODL",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1521763200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1521763200,
    "objectID": "104734ed72d9e7a28b7f207d8ea7c150",
    "permalink": "http://jonasadler.com/talk/2018hpsc/",
    "publishdate": "2018-03-23T00:00:00Z",
    "relpermalink": "/talk/2018hpsc/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: What Can We Expect? Computable Upper Bounds to Machine Learning in Inverse Problems Using MCMC",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1520553600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1520553600,
    "objectID": "c9a6538e8d8f7b9aa5fcbe2ae8aa7113",
    "permalink": "http://jonasadler.com/talk/2018ssba/",
    "publishdate": "2018-03-09T00:00:00Z",
    "relpermalink": "/talk/2018ssba/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Contributed talk: Learned iterative reconstruction",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1512777600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1512777600,
    "objectID": "9efa24a642e296792440ae41ecc9d873",
    "permalink": "http://jonasadler.com/talk/2017nips/",
    "publishdate": "2017-12-09T00:00:00Z",
    "relpermalink": "/talk/2017nips/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Poster: Learning to solve inverse problems using Wasserstein Loss",
    "type": "talk"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1509408000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1509408000,
    "objectID": "d03a874e09588a75b2716027883f02fd",
    "permalink": "http://jonasadler.com/talk/2017generative_models_parameter/",
    "publishdate": "2017-10-31T00:00:00Z",
    "relpermalink": "/talk/2017generative_models_parameter/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Contributed talk: Learned forward operators: Variational regularization for black-box models",
    "type": "talk"
  },
  {
    "authors": [
      "Jonas Adler",
      "Axel Ringh",
      "Ozan Öktem",
      "Johan Karlsson"
    ],
    "categories": null,
    "content": "",
    "date": 1509321600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1509321600,
    "objectID": "5a431fafe315b3b5d946176545ee75f9",
    "permalink": "http://jonasadler.com/publication/learning_inverse_wasserstein/",
    "publishdate": "2017-10-30T00:00:00Z",
    "relpermalink": "/publication/learning_inverse_wasserstein/",
    "section": "publication",
    "summary": "We propose using the Wasserstein loss for training in inverse problems. In particular, we consider a learned primal-dual reconstruction scheme for ill-posed inverse problems using the Wasserstein distance as loss function in the learning. This is motivated by miss-alignments in training data, which when using standard mean squared error loss could severely degrade reconstruction quality. We prove that training with the Wasserstein loss gives a reconstruction operator that correctly compensates for miss-alignments in certain cases, whereas training with the mean squared error gives a smeared reconstruction. Moreover, we demonstrate these effects by training a reconstruction algorithm using both mean squared error and optimal transport loss for a problem in computerized tomography.",
    "tags": [],
    "title": "Learning to solve inverse problems using Wasserstein loss",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1505689200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1505689200,
    "objectID": "3547c6d3e7914c10d56b06510a23aabd",
    "permalink": "http://jonasadler.com/talk/2017variationalmethodsml/",
    "publishdate": "2017-09-18T00:00:00+01:00",
    "relpermalink": "/talk/2017variationalmethodsml/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: Learned iterative reconstruction schemes, theory and practice",
    "type": "talk"
  },
  {
    "authors": [
      "Andreas Hauptmann",
      "Felix Lucka",
      "Marta Betcke",
      "Nam Huynh",
      "Jonas Adler",
      "Ben Cox",
      "Paul Beard",
      "Sebastien Ourselin",
      "Simon Arridge"
    ],
    "categories": null,
    "content": "",
    "date": 1504134000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1504134000,
    "objectID": "09a06b4e56a1f6bb3f2e757d694750ea",
    "permalink": "http://jonasadler.com/publication/model-based-learning-photoacoustic/",
    "publishdate": "2017-08-31T00:00:00+01:00",
    "relpermalink": "/publication/model-based-learning-photoacoustic/",
    "section": "publication",
    "summary": "Recent advances in deep learning for tomographic reconstructions have shown great potential to create accurate and high quality images with a considerable speed-up. In this work we present a deep neural network that is specifically designed to provide high resolution 3D images from restricted photoacoustic measurements. The network is designed to represent an iterative scheme and incorporates gradient information of the data fit to compensate for limited view artefacts. Due to the high complexity of the photoacoustic forward operator, we separate training and computation of the gradient information. A suitable prior for the desired image structures is learned as part of the training. The resulting network is trained and tested on a set of segmented vessels from lung CT scans and then applied to in-vivo photoacoustic measurement data.",
    "tags": [],
    "title": "Model based learning for accelerated, limited-view 3D photoacoustic tomography",
    "type": "publication"
  },
  {
    "authors": [
      "Jonas Adler"
    ],
    "categories": [],
    "content": "An introduction to some Machine Learning methods for image reconstruction.\n\nSuppose that you were given a blurred image:\nThen you could probably tell that it was generated from this image:\nBut what about if you instead were given indirect observations of the image, such as the line integrals taken over some set of lines:\nWould you still tell it came from the image above? Probably not. But we will demonstrate how we can teach a computer to do it.\nIntroduction These problems are called the deblurring and radon inversion problems respectively and are both examples of inverse problems. In inverse problem we seek to find (reconstruct) some parameter given indirect observations. Mathematically this can be stated as finding some parameter $f$ that are connected to measured data $g$ through a known forward model $\\mathcal{T}$:\n$$ g = \\mathcal{T}(f) + noise $$\nSeveral classical image processing problems such as denoising, inpainting, deblurring and superresolution can be cast into this form, but it is also a good model for more complicated problems such as Magnetic Resonance Imaging (MRI) and Computed Tomography (CT).\nMachine learning for inverse problems If the forward model is local, such as in deblurring where each datapoint is affected only by a small neighborhood of the image, finding the unknown parameter from data using machine learning is at least on a conceptual level straightforward. Simply use any standard convolutional neural network and known pairs $(g, f_{\\text{true}})$ and train the neural network to map $g$ to $f_{\\text{true}}$.\nBut what happens when $\\mathcal{T}$ is more complicated? In Computed Tomography, the parameter $f$ is an image of the interior of the patient and the forward model is given by the Radon Transform which computes all line integrals of the image:\n$$ \\mathcal{T}(f)(\\ell) = \\int_{\\ell} f(x) dx \\quad \\ell \\text{ is a line in } \\mathbb{R}^2 $$\nIf we compare this to the deblurring problem, we see that while the deblurring problem has a local relationship between parameter and data, the radon transform has a global relationship. Here two points on opposite sides of the image can still influence the same datapoint as long as they lie on the same line. And since the forward model is global, so is the inverse problem. This means that classical local machine-learning approaches based on convolutions will not work.\nOne way to solve this would be to use fully-connected layers instead of convolutions, but this quickly becomes infeasible. For example in the example above a single fully connected layer between data and signal would require a staggering $2.6 \\cdot 10^{11}$ weights. Storing these in single precision would require one terabyte of memory. For a single layer.\nThis is obviously not a workable solution.\nLearned denoisers One of the most obvious solutions to this is to somehow recast the problem to an image-to-image problem. The most popular way of doing this is to first perform some initial (non machine-learning) reconstruction, e.g. Filtered Back-Projection (FBP):\n Once this is done we can use any standard machine-learning approach to \u0026ldquo;denoise\u0026rdquo; the initial reconstruction by training a neural network to take the initial reconstruction as data and return the ground truth.\nSeveral groups have done this and the results are in fact quite remarkable, outperforming previous state of the art methods:\nHowever, the method leaves a sour taste. Sure the images certainly look better, but the only input was the initial reconstruction, so could it truly show anything that wasn\u0026rsquo;t already there?\nLearned Primal-Dual This observation leads to a painful conclusion: in order to obtain a reconstruction with more information than current reconstruction methods, we need to work directly from raw data. But as we noted above, fully learning how to do this is practically impossible.\nThe solution is to take a middle way, to incorporate enough a-priori information to make the problem tractable and then learn the rest.\nThe most powerful prior information we have is the forward operator $\\mathcal{T}$, but it only maps images to data. How would we go from data to images? One answer is to use the adjoint operator $\\mathcal{T}^*$.\nThe idea of our proposed solution (called the Learned Primal-Dual algorithm) is to use these operators alternatively. First we use a convolutional neural network to update the data (a so called dual step), then apply $\\mathcal{T}^*$ and use the result as input to another neural network which updates the reconstruction (the primal step), then apply $\\mathcal{T}$ and use it as input to a neural network that updates the data, and so on. This is iteratively performed a few times (10 in our experiments), at which point we have a final reconstruction.\nWe train end-to-end with raw measured data as input and the reconstruction as output, without any initial reconstruction or other external information.\nThe good thing about this is that we separate the global aspect of the problem into the forward model and its adjoint and only need to learn the local aspects. The bad thing is that to train the network we need to perform back-propagation through this neural network that among others contain 10 calls to the forward operator, 10 calls the the adjoint operator and 20 small neural networks in between. We did this using some magic with Operator Discretization Library ODL and TensorFlow.\nResults If you ask me, the results look quite good and I especially appreciate that the method is able to avoid some artifacts (some examples shown with red arrows) that the denoiser wasn\u0026rsquo;t able:\nThe quantitative results are also quite good and we outperform learned denoising w.r.t both Peak Signal to Noise Ratio (PSNR) and structural similarity index (SSIM). The runtime is not too shabby either and we manage to do all of this using only $2\\%$ of the trainable parameters used in the denoiser.\n   Method PSNR (dB) SSIM Runtime (ms) Parameters     FBP 33.65 0.83 423 1   Denoiser 41.92 0.94 463 $10^7$   Proposed 44.11 0.97 620 $2.4 \\cdot 10^5$    Read more If you found this interesting you should read our article \u0026ldquo;Learned Primal-Dual Reconstruction\u0026rdquo; on arXiv which describes the method in depth and gives a broader overview of what others have done in this exciting field. You could also have a look on the source code.\n",
    "date": 1500678000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1500678000,
    "objectID": "c01a254f5d468af9531669f9731fed4c",
    "permalink": "http://jonasadler.com/post/learning_to_reconstruct/",
    "publishdate": "2017-07-22T00:00:00+01:00",
    "relpermalink": "/post/learning_to_reconstruct/",
    "section": "post",
    "summary": "An introduction to some Machine Learning methods for image reconstruction.\n\n",
    "tags": [],
    "title": "Learning to reconstruct",
    "type": "post"
  },
  {
    "authors": [
      "Jonas Adler",
      "Ozan Öktem"
    ],
    "categories": null,
    "content": "",
    "date": 1499209200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1499209200,
    "objectID": "f6dd136d7f348db904da1e87c9d23963",
    "permalink": "http://jonasadler.com/publication/learned-primal-dual/",
    "publishdate": "2017-07-05T00:00:00+01:00",
    "relpermalink": "/publication/learned-primal-dual/",
    "section": "publication",
    "summary": "We propose the Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm accounts for a (possibly non-linear) forward operator in a deep neural network by unrolling a proximal primal-dual optimization method, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and it does not depend on any initial reconstruction such as FBP. We compare performance of the proposed method on low dose CT reconstruction against FBP, TV, and deep learning based post-processing of FBP. For the Shepp-Logan phantom we obtain 6dB PSNR improvement against all compared methods. For human phantoms the corresponding improvement is 6.6dB over TV and 2.2dB over learned post-processing along with a substantial improvement in the SSIM. Finally, our algorithm involves only ten forward-back-projection computations, making the method feasible for time critical clinical applications.",
    "tags": [],
    "title": "Learned Primal-Dual Reconstruction",
    "type": "publication"
  },
  {
    "authors": [
      "Jonas Adler",
      "Gregory J. Bootsma",
      "Håkan Nordström",
      "Markus Eriksson"
    ],
    "categories": null,
    "content": "",
    "date": 1496271600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1496271600,
    "objectID": "7965246fe4724ec576306123a0083f61",
    "permalink": "http://jonasadler.com/publication/gpumci/",
    "publishdate": "2017-06-01T00:00:00+01:00",
    "relpermalink": "/publication/gpumci/",
    "section": "publication",
    "summary": "Spectral CT allows reconstructing a set of materialselective basis images which can be used for material quantification. These basis images can be reconstructed independently of each other or treated as a joint reconstruction problem. In this work, we investigate the effect of two ways of introducing coupling between the basis images: using an anti-correlated noise model and regularizing the basis images with a joint prior. We simulate imaging of a FORBILD Head phantom with an ideal photon-counting detector and reconstruct the resulting basis sinograms with and without these two kinds of coupling. The results show that the anti-correlated noise model gives better spatial resolution than the uncorrelated noise model at the same noise level, but also introduces artifacts. If anti-correlations are introduced also in the prior, these artifacts are reduced and the resolution is improved further.",
    "tags": [],
    "title": "GPUMCI: a flexible platform for x-ray imaging on the GPU",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1496185200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1496185200,
    "objectID": "42204865408218b4d054777dab34a4d1",
    "permalink": "http://jonasadler.com/talk/2017aip/",
    "publishdate": "2017-05-31T00:00:00+01:00",
    "relpermalink": "/talk/2017aip/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "Invited talk: Using deep learning to reconstruct multi-modal images - A primal dual scheme with examples in PET-MRI",
    "type": "talk"
  },
  {
    "authors": [
      "Jonas Adler",
      "Ozan Öktem"
    ],
    "categories": null,
    "content": "",
    "date": 1492038000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1492038000,
    "objectID": "ae14ee81203620eb6e16a326d33c3dc4",
    "permalink": "http://jonasadler.com/publication/learning-to-solve/",
    "publishdate": "2017-04-13T00:00:00+01:00",
    "relpermalink": "/publication/learning-to-solve/",
    "section": "publication",
    "summary": "We propose a partially learned approach for the solution of ill-posed inverse problems with not necessarily linear forward operators. The method builds on ideas from classical regularisation theory and recent advances in deep learning to perform learning while making use of prior information about the inverse problem encoded in the forward operator, noise model and a regularising functional. The method results in a gradient-like iterative scheme, where the 'gradient' component is learned using a convolutional network that includes the gradients of the data discrepancy and regulariser as input in each iteration.\nWe present results of such a partially learned gradient scheme on a non-linear tomographic inversion problem with simulated data from both the Sheep-Logan phantom as well as a head CT. The outcome is compared against filtered backprojection and total variation reconstruction and the proposed method provides a 5.4 dB PSNR improvement over the total variation reconstruction while being significantly faster, giving reconstructions of $512 \\times 512$ pixel images in about 0.4 s using a single graphics processing unit (GPU).",
    "tags": [],
    "title": "Solving ill-posed inverse problems using iterative deep neural networks",
    "type": "publication"
  },
  {
    "authors": [
      "Awais Ashfaq",
      "Jonas Adler"
    ],
    "categories": null,
    "content": "",
    "date": 1483228800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1483228800,
    "objectID": "cf9f2a8bfc89a9cda96f2869e38ea517",
    "permalink": "http://jonasadler.com/publication/a_modified_fuzzy_c_means/",
    "publishdate": "2017-01-01T00:00:00Z",
    "relpermalink": "/publication/a_modified_fuzzy_c_means/",
    "section": "publication",
    "summary": "",
    "tags": [],
    "title": "A modified fuzzy C means algorithm for shading correction in craniofacial CBCT images",
    "type": "publication"
  },
  {
    "authors": [
      "Mats Persson",
      "Jonas Adler"
    ],
    "categories": null,
    "content": "",
    "date": 1483228800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1483228800,
    "objectID": "2864a2b78309c43ad30b93d0cc21b2b2",
    "permalink": "http://jonasadler.com/publication/spectral_ct_anticorrelated/",
    "publishdate": "2017-01-01T00:00:00Z",
    "relpermalink": "/publication/spectral_ct_anticorrelated/",
    "section": "publication",
    "summary": "Spectral CT allows reconstructing a set of materialselective basis images which can be used for material quantification. These basis images can be reconstructed independently of each other or treated as a joint reconstruction problem. In this work, we investigate the effect of two ways of introducing coupling between the basis images: using an anti-correlated noise model and regularizing the basis images with a joint prior. We simulate imaging of a FORBILD Head phantom with an ideal photon-counting detector and reconstruct the resulting basis sinograms with and without these two kinds of coupling. The results show that the anti-correlated noise model gives better spatial resolution than the uncorrelated noise model at the same noise level, but also introduces artifacts. If anti-correlations are introduced also in the prior, these artifacts are reduced and the resolution is improved further.",
    "tags": [],
    "title": "Spectral CT reconstruction with anti-correlated noise model and joint prior",
    "type": "publication"
  },
  {
    "authors": [
      "Jonas Adler"
    ],
    "categories": [],
    "content": "Instructions for installing and configuring Ubuntu 16.04 LTE on a PC with two GPUs.\n\nThe primary GPU will be used for computations and the secondary one will be used for displaying graphics. In this example, the computer is a HP Z640 with NVIDIA Titan-X Pascal as primary GPU and a NVIDIA Quadro K620 as secondary GPU.\nNote: if the computer already have a working installation of Ubuntu 16.04 with build-essentials installed you should (probably) not have to reinstall it, meaning that the first two steps can be skipped. Moreover, sometimes the installation procedure works also without removing the secondary GPU (see step 1 and step 22).\n Turn off computer, ensure only the primary GPU is connected to the motherboard. Boot from USB with Ubuntu 16.04 LTS installation, install a fresh copy of Ubuntu 16.04 LTS but keep Windows partitions intact, e.g. by choosing \u0026ldquo;Erase Ubuntu xx.yy and reinstall\u0026rdquo;\n Install build essentials.\n$ sudo apt-get install build-essential  Go to https://developer.nvidia.com/cuda-downloads and download the latest CUDA toolkit for Ubuntu 16.04 by selecting the following in the web-interface that is offered:\n Operating system: Linux Architecture: x86_64 Distribution: Ubuntu Version: 16.04 Installer Type: runfile (local)  This will download the latest version, which in the instructions will be is version 8.0.44, so the file that will be downloaded is \u0026ldquo;cuda_8.0.44_linux.run\u0026rdquo;\n Open up a terminal and extract the separate installers via:\n$ mkdir ~/Downloads/nvidia_installers $ cd ~/Downloads $ sudo chmod a+x ./cuda_8.0.44_linux.run $ ./cuda_8.0.44_linux.run -extract=~/Downloads/nvidia_installers  Completely uninstall anything in the ubuntu repositories with nvidia-*. I used synaptic and did a purge, AKA completely uninstall programs and configuration.\n$ sudo apt-get --purge remove nvidia-*  No need to create an xorg.conf file. If you have one, remove it (assuming you have a fresh OS install).\n$ sudo rm /etc/X11/xorg.conf  Create the /etc/modprobe.d/blacklist-nouveau.conf file with the 2 following lines:\nblacklist nouveau options nouveau modeset=0  Then do a\n$ sudo update-initramfs -u  Reboot computer. Nothing should have changed in loading up menu. You should be taken to the login screen. Once there type: Ctrl + Alt + F1, and login to your user. Keep the next commands handy in another machine since now you are in tty.\n In tty:\ncd ~/Downloads/nvidia_installers sudo service lightdm stop  The top line is a necessary step for installing the driver.\n Now type\nsudo ./NVIDIA-Linux-x86_64-367.48.run --no-opengl-files  The file \u0026ldquo;NVIDIA-Linux-x86_64-367.48.run\u0026rdquo; should have been created by the extract command at step (4.) above. It is important to include the opengl flag in the above command. If you miss that, either you will get stuck in ?login loop? or your computer would boot with a black screen at all times.\nAt some point you will get a warning message about 32-bit support, answer ok.\nWhen prompted \u0026ldquo;The distribution-provided pre-installed script failed are you sure you want to continue\u0026rdquo;. Answer continue.\nIf prompted to over-write xorg.conf, answer yes.\nPick defaults for all other options.\n Now install the toolkit also\nsudo ./cuda-linux64-rel-8.0.44-21122537.run sudo ./cuda-samples-linux-8.0.44-21122537.run  Both the run-files above are suppose to have been created by the extract command at step (4.) above.\nPick defaults to all questions.\nPick yes for symbolic links.\n Set Environment path variables in .bashrc:\nexport PATH=/usr/local/cuda/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH  Reload bash in order to apply these settings\n$ exec bash  Verify the driver version:\n$ cat /proc/driver/nvidia/version NVRM version: NVIDIA UNIX x86_64 Kernel Module 367.48 Sat Sep 3 18:21:08 PDT 2016 GCC version: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1)  Check CUDA driver version:\n$ nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Sun_Sep__4_22:14:01_CDT_2016 Cuda compilation tools, release 8.0, V8.0.44  At this point you can switch the lightdm back on again by doing:\n$ sudo service lightdm start  Shut down computer, insert secondary GPU which in this example is a Quadro K620 card. Keep the display connected to the primary GPU.\n Boot computer, log in.\n Check that both GPU cards are recognized by the system, by typing\n$ nvidia-smi Mon Jan 9 14:47:10 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.48 Driver Version: 367.48 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 TITAN X (Pascal) Off | 0000:02:00.0 Off | N/A | | 34% 44C P8 17W / 250W | 129MiB / 12187MiB | 4% Default | |-------------------------------+----------------------+----------------------+ | 1 Quadro K620 Off | 0000:03:00.0 On | N/A | | 24% 41C P0 3W / 30W | 1MiB / 2000MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 3954 G /usr/lib/xorg/Xorg 128MiB | +-----------------------------------------------------------------------------+  Generate Nvidia X11 configuration file and activate multiple GPU option:\n$ sudo nvidia-xconfig -multigpu=on  Set the secondary GPU as the default GPU device for displaying graphics.\nFind the PCI port of the secondary GPU by typing\n$ nvidia-smi -a  In the output that follow, find the PCI bus related to the secondary GPU. Simply look for text in output where the \u0026ldquo;Product Name\u0026rdquo; matches the secondary GPU and read the PCI bus number.\nIn my current output is given below, the PCI bus is \u0026ldquo;3\u0026rdquo;:\n[...] GPU 0000:03:00.0 Product Name : Quadro K620 Product Brand : Quadro Display Mode : Enabled Display Active : Enabled Persistence Mode : Disabled Accounting Mode : Disabled Accounting Mode Buffer Size : 1920 Driver Model Current : N/A Pending : N/A Serial Number : 0324114080422 GPU UUID : GPU-4c631408-4129-9d5d-fbf3-0588bc1ab5cf Minor Number : 1 VBIOS Version : 82.07.4E.00.0E MultiGPU Board : No Board ID : 0x300 GPU Part Number : N/A Inforom Version Image Version : 2012.0504.00.03 OEM Object : 1.1 ECC Object : N/A Power Management Object : N/A GPU Operation Mode Current : N/A Pending : N/A GPU Virtualization Mode Virtualization mode : None PCI Bus : 0x03 Device : 0x00 Domain : 0x0000 Device Id : 0x13BB10DE Bus Id : 0000:03:00.0 [...]  Update X11 configuration file.\n$ sudo pico /etc/X11/xorg.conf  Find the section\nSection \u0026quot;Device\u0026quot; Identifier \u0026quot;Device0\u0026quot; Driver \u0026quot;nvidia\u0026quot; VendorName \u0026quot;NVIDIA Corporation\u0026quot; EndSection  and replace with\nSection \u0026quot;Device\u0026quot; Identifier \u0026quot;Device0\u0026quot; Driver \u0026quot;nvidia\u0026quot; VendorName \u0026quot;NVIDIA Corporation\u0026quot; BusID \u0026quot;PCI:3:0:0\u0026quot; EndSection  Here, \u0026ldquo;3\u0026rdquo; should match the PCI bus as determined above.\n Shutdown computer. Switch display cable so that it is connected to the secondary GPU. Start computer.\n Validate that both GPUs are active and that the secondary GPU is used\n$ nvidia-smi Mon Jan 9 14:56:11 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.48 Driver Version: 367.48 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 TITAN X (Pascal) Off | 0000:02:00.0 Off | N/A | | 24% 41C P0 17W / 250W | 1MiB / 12187MiB | 0% Default | |-------------------------------+----------------------+----------------------+ | 1 Quadro K620 Off | 0000:03:00.0 On | N/A | | 34% 44C P8 3W / 30W | 129MiB / 2000MiB | 4% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 1 3954 G /usr/lib/xorg/Xorg 128MiB | +-----------------------------------------------------------------------------+   Acknowledgement This guide largely follows Installing CUDA with Ubuntu, but has been updated for Ubuntu 16.04 and two GPUs. Ozan Öktem helped compile the notes.\n",
    "date": 1482883200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1482883200,
    "objectID": "6075bebe14ed60f04d9be682fc63f1af",
    "permalink": "http://jonasadler.com/post/install_cuda/",
    "publishdate": "2016-12-28T00:00:00Z",
    "relpermalink": "/post/install_cuda/",
    "section": "post",
    "summary": "Instructions for installing and configuring Ubuntu 16.04 LTE on a PC with two GPUs.\n\n",
    "tags": [],
    "title": "Dual GPU configuration in Ubuntu 16.04 and CUDA 8.0",
    "type": "post"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1447545600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1447545600,
    "objectID": "60e56b82730d508963c12e10c1397df2",
    "permalink": "http://jonasadler.com/talk/2015ieeemic/",
    "publishdate": "2015-11-15T00:00:00Z",
    "relpermalink": "/talk/2015ieeemic/",
    "section": "talk",
    "summary": "",
    "tags": [],
    "title": "ODL: A python library for inverse problems",
    "type": "talk"
  }
]