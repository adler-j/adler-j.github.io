// = Your Blog title
// See https://hubpress.gitbooks.io/hubpress-knowledgebase/content/ for information about the parameters.
// :hp-image: /covers/cover.png
// :published_at: 2019-01-31
// :hp-tags: HubPress, Blog, Open_Source,
// :hp-alt-title: My English Title

:stem: latexmath

= Learning to reconstruct

If I gave you this data:

image::mayo_data.png[mayo_data]

would you be able to tell that it was generated from this object?

image:mayo_phantom.png[mayo_phantom]

Perhaps not, but we can teach a computer to do it.

== An introduction to inverse problems

Inverse problems refer to problems where one seeks to reconstruct some parameters  from indirect observations. Mathematically we have

[stem]
+++++++++++++++++
g = \mathcal{T}(f) + noise
+++++++++++++++++

where stem:[g] is our measured data and stem:[f] is the signal we want to reconstruct. These are connected through the _forward model_ stem:[\mathcal{T}], which describes how some set of parameters gives rise to an observation.

Several cases of classical image processing problems can be cast into this form, including denoising, inpainting, superresolution, etc. But it is also a good model for more complicated modalities such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI), etc.

== Machine learning for inverse problems

If stem:[\mathcal{T}] is an operator that maps images to images, such as the identity operator (denoising) or perhaps a subsampling (inpainting, superresolution), finding stem:[f] from stem:[g] using machine learning is in some sense trivial (at least on a conceptual level), and any architecture such as Denoising Autoencoders, Generative Advesarial Networks, etc could be used to learn a transformation from stem:[g] to stem:[f].

But what happens when stem:[\mathcal{T}] is more complicated? We'll focus on CT, where the forward model is given by the https://en.wikipedia.org/wiki/Radon_transform[Radon transform]

[stem]
+++++++++++++++++
\mathcal{T}(\signal)(\ell) = \int_{\ell} f(x) dx
+++++++++++++++++

