<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Jonas Adler]]></title><description><![CDATA[Ramblings on programming and mathematics]]></description><link>https://adler-j.github.io</link><generator>RSS for Node</generator><lastBuildDate>Fri, 21 Jul 2017 19:52:37 GMT</lastBuildDate><atom:link href="https://adler-j.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Learning to reconstruct]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Suppose that you were given a smoothed image:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://adler-j.github.io/images/mayo_convolved.png" alt="mayo_convolved" width="300" height="300">
</div>
</div>
<div class="paragraph">
<p>Then you could probably tell that it was generated from this image:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_phantom.png" alt="mayo_phantom" width="300" height="300"></span></p>
</div>
<div class="paragraph">
<p>But what about if I instead gave you the line integrals of the image:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_data.png" alt="mayo_data" width="300" height="300"></span></p>
</div>
<div class="paragraph">
<p>Would you still tell it came from the image above? Probably not. But we will demonstrate how we can teach a computer to do it.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_an_introduction_to_inverse_problems">An introduction to inverse problems</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In inverse problems we seeks to find (reconstruct) some parameters given indirect observations. Mathematically this can be stated as finding some parameters \(f\) that is connected to our measured data \(g\) through the <em>forward model</em> \(\mathcal{T}\):</p>
</div>
<div class="stemblock">
<div class="content">
\[g = \mathcal{T}(f) + noise\]
</div>
</div>
<div class="paragraph">
<p>Several classical image processing problems can be cast into this form, including denoising, inpainting, deconvolution and superresolution. But it is also a good model for more complicated modalities such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI), etc.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_machine_learning_for_inverse_problems">Machine learning for inverse problems</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If \(\mathcal{T}\) maps images to images, such as the convolution above, finding \(f\) from \(g\) using machine learning is at least on a conceptual level trivial, and any architecture such as Denoising Autoencoders, Generative Advesarial Networks, etc could be used to learn a transformation from \(g\) to \(f\).</p>
</div>
<div class="paragraph">
<p>But what happens when \(\mathcal{T}\) is more complicated?
We&#8217;ll focus on CT, where the forward model is given by the <a href="https://en.wikipedia.org/wiki/Radon_transform">Radon transform</a></p>
</div>
<div class="stemblock">
<div class="content">
\[\mathcal{T}(f)(\ell) = \int_{\ell} f(x) dx  \quad \ell \text{ is a line in } \mathbb{R}^2\]
</div>
</div>
<div class="paragraph">
<p>The main complication here is that we have a global relationship between signal and data, where two widely separated points in an image can both influence a point in data. And since the forward model is global, so is the inverse problem. This means that classical machine-learning approaches based on convolutions will not work.</p>
</div>
<div class="paragraph">
<p>One way to solve this would be to use fully-connected layers instead of convolutions, but this quickly becomes infeasible. For example, in the example above the data has size \(1000 \times 1000 = 10^6\), and the signal \(512 \times 512 = 2.6 \cdot 10^5\). A single fully connected layer between these would require a staggering \(10^6 \cdot 2.6 \cdot 10^5 = 2.6 \cdot 10^{11}\) weights. Storing these in single precision would require one terrabyte of data. For a single layer.</p>
</div>
<div class="paragraph">
<p>This is obviously not a workable solution.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_denoisers">Learned denoisers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>One of the most obvious solutions to this problem is to somehow re-cast the problem back into a image-to-image problem. The most popular way of doing this is to first apply some initial reconstruction, e.g. <a href="https://en.wikipedia.org/wiki/Radon_transform#Radon_inversion_formula">Filtered Back-Projection</a> (FBP):</p>
</div>
<div class="videoblock">
<div class="content">
<video src="https://adler-j.github.io/images/mayo_fbp_animation.mp4" width="600" height="309" poster="https://adler-j.github.io/images/mayo_fbp_animation" autoplay controls loop>
Your browser does not support the video tag.
</video>
</div>
</div>
<div class="paragraph">
<p>Once this has been applied, we can use any standard machine-learning approach to "denoise" the result by training a neural network to take low quality images as input and return high quality images.</p>
</div>
<div class="paragraph">
<p>Several people have done this and the results are in fact quite remarkable:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/learned_denoiser.png" alt="mayo_data" width="800" height="309"></span></p>
</div>
<div class="paragraph">
<p>However, these methods leave a sour after-taste. Sure the images look better, but the only input they had was the low quality image. Hence they cannot possibly show something that was not present in the low quality image. So is the denoised image truly better?</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_primal_dual">Learned Primal-Dual</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This observation leads us to a painful conclusion: in order to get a reconstruction that contains more information than current reconstructions, we <em>need</em> to work directly from raw data. But as we noted above, learning how to do this is practually impossible.</p>
</div>
<div class="paragraph">
<p>A solution is to</p>
</div>
</div>
</div>]]></description><link>https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html</link><guid isPermaLink="true">https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html</guid><dc:creator><![CDATA[Jonas Adler]]></dc:creator><pubDate>Fri, 21 Jul 2017 00:00:00 GMT</pubDate></item><item><title><![CDATA[Dual GPU configuration in Ubuntu 16.04 and CUDA 8.0]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Instructions for installing and configuring Ubuntu 16.04 LTE on a PC with two GPUs.
The primary GPU will be used for computations and the secondary one will be used for displaying graphics.
In this example, the computer is a HP Z640 with NVIDIA Titan-X Pascal as primary GPU and a NVIDIA Quadro K620 as secondary GPU.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Turn off computer, ensure only the primary GPU is connected to the motherboard.
Boot from USB with Ubuntu 16.04 LTS installation,
install a fresh copy of Ubuntu 16.04 LTS but keep Windows partitions intact,
e.g. by choosing "Erase Ubuntu xx.yy and reinstall"</p>
</li>
<li>
<p>Install build essentials.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get install build-essential</pre>
</div>
</div>
</li>
<li>
<p>Go to <a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a> and download latest CUDA toolkit for Ubuntu 16.04 by selecting the following in the web-interface that is offered:</p>
<div class="ulist">
<ul>
<li>
<p>Operating system: Linux</p>
</li>
<li>
<p>Architecture: x86_64</p>
</li>
<li>
<p>Distribution: Ubuntu</p>
</li>
<li>
<p>Version: 16.04</p>
</li>
<li>
<p>Installer Type: runfile (local)</p>
<div class="paragraph">
<p>This will download the latest version,
which in the instructions will be is version 8.0.44,
so the file that will be downloaded is "cuda_8.0.44_linux.run"</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Open up a terminal and extract the separate installers via:</p>
<div class="literalblock">
<div class="content">
<pre>$ mkdir ~/Downloads/nvidia_installers
$ cd ~/Downloads
$ sudo chmod a+x ./cuda_8.0.44_linux.run
$ ./cuda_8.0.44_linux.run -extract=~/Downloads/nvidia_installers</pre>
</div>
</div>
</li>
<li>
<p>Completely uninstall anything in the ubuntu repositories with nvidia-*. I used synaptic and did a purge, AKA completely uninstall programs and configuration.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get --purge remove nvidia-*</pre>
</div>
</div>
</li>
<li>
<p>No need to create an xorg.conf file. If you have one, remove it (assuming you have a fresh OS install).</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo rm /etc/X11/xorg.conf</pre>
</div>
</div>
</li>
<li>
<p>Create the /etc/modprobe.d/blacklist-nouveau.conf file with the 2 following lines:</p>
<div class="literalblock">
<div class="content">
<pre>blacklist nouveau
options nouveau modeset=0</pre>
</div>
</div>
<div class="paragraph">
<p>Then do a</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo update-initramfs -u</pre>
</div>
</div>
</li>
<li>
<p>Reboot computer. Nothing should have changed in loading up menu.
You should be taken to the login screen.
Once there type: Ctrl + Alt + F1, and login to your user.
Keep the next commands handy in another machine since now you are in tty.</p>
</li>
<li>
<p>In tty:</p>
<div class="literalblock">
<div class="content">
<pre>cd ~/Downloads/nvidia_installers
sudo service lightdm stop</pre>
</div>
</div>
<div class="paragraph">
<p>The top line is a necessary step for installing the driver.</p>
</div>
</li>
<li>
<p>Now type</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./NVIDIA-Linux-x86_64-367.48.run --no-opengl-files</pre>
</div>
</div>
<div class="paragraph">
<p>The file "NVIDIA-Linux-x86_64-367.48.run" should have been created by the extract command at step (4.) above. It is important to include the opengl flag in the above command. If you miss that, either you will get stuck in ?login loop? or your computer would boot with a black screen at all times.</p>
</div>
<div class="paragraph">
<p>At some point you will get a warning message about 32-bit support, answer ok.</p>
</div>
<div class="paragraph">
<p>When prompted "The distribution-provided pre-installed script failed are you sure you want to continue". Answer continue.</p>
</div>
<div class="paragraph">
<p>If prompted to over-write xorg.conf, answer yes.</p>
</div>
<div class="paragraph">
<p>Pick defaults for all other options.</p>
</div>
</li>
<li>
<p>Now install the toolkit also</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./cuda-linux64-rel-8.0.44-21122537.run
sudo ./cuda-samples-linux-8.0.44-21122537.run</pre>
</div>
</div>
<div class="paragraph">
<p>Both the run-files above are suppose to have been created by the extract command at step (4.) above.</p>
</div>
<div class="paragraph">
<p>Pick defaults to all questions.</p>
</div>
<div class="paragraph">
<p>Pick yes for symbolic links.</p>
</div>
</li>
<li>
<p>Set Environment path variables in .bashrc:</p>
<div class="literalblock">
<div class="content">
<pre>export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</pre>
</div>
</div>
</li>
<li>
<p>Reload bash in order to apply these settings</p>
<div class="literalblock">
<div class="content">
<pre>$ exec bash</pre>
</div>
</div>
</li>
<li>
<p>Verify the driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module    367.48    Sat Sep    3 18:21:08 PDT 2016
GCC version:    gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1)</pre>
</div>
</div>
</li>
<li>
<p>Check CUDA driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44</pre>
</div>
</div>
</li>
<li>
<p>At this point you can switch the lightdm back on again by doing:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo service lightdm start</pre>
</div>
</div>
</li>
<li>
<p>Shut down computer, insert secondary GPU which in this example is a Quadro K620 card.</p>
</li>
<li>
<p>Boot computer, log in.</p>
</li>
<li>
<p>Check that both GPU cards are recognized by the system, by typing</p>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi
Mon Jan    9 14:47:10 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 34%   44C    P8    17W / 250W |    129MiB / 12187MiB |      4%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 24%   41C    P0     3W /  30W |      1MiB /  2000MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+</pre>
</div>
</div>
</li>
<li>
<p>Generate Nvidia X11 configuration file and activate multiple GPU option:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo nvidia-xconfig -multigpu=on</pre>
</div>
</div>
</li>
<li>
<p>Set the secondary GPU as the default GPU device for displaying graphics.</p>
<div class="paragraph">
<p>Find the PCI port of the secondary GPU by typing</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi -a</pre>
</div>
</div>
<div class="paragraph">
<p>In the output that follow, find the PCI bus related to the secondary GPU. Simply look for text in output where the "Product Name" matches the secondary GPU and read the PCI bus number.</p>
</div>
<div class="paragraph">
<p>In my current output is given below, the PCI bus is "3":</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[...]
GPU 0000:03:00.0
    Product Name                    : Quadro K620
    Product Brand                   : Quadro
    Display Mode                    : Enabled
    Display Active                  : Enabled
    Persistence Mode                : Disabled
    Accounting Mode                 : Disabled
    Accounting Mode Buffer Size     : 1920
    Driver Model
        Current                     : N/A
        Pending                     : N/A
    Serial Number                   : 0324114080422
    GPU UUID                        : GPU-4c631408-4129-9d5d-fbf3-0588bc1ab5cf
    Minor Number                    : 1
    VBIOS Version                   : 82.07.4E.00.0E
    MultiGPU Board                  : No
    Board ID                        : 0x300
    GPU Part Number                 : N/A
    Inforom Version
        Image Version               : 2012.0504.00.03
        OEM Object                  : 1.1
        ECC Object                  : N/A
        Power Management Object     : N/A
    GPU Operation Mode
        Current                     : N/A
        Pending                     : N/A
    GPU Virtualization Mode
        Virtualization mode         : None
    PCI
        Bus                         : 0x03
        Device                      : 0x00
        Domain                      : 0x0000
        Device Id                   : 0x13BB10DE
        Bus Id                      : 0000:03:00.0
[...]</pre>
</div>
</div>
<div class="paragraph">
<p>Update X11 configuration file.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo pico /etc/X11/xorg.conf</pre>
</div>
</div>
<div class="paragraph">
<p>Find the section</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>and replace with</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
    BusID          "PCI:3:0:0"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>Here, "3" should match the PCI bus as determined above.</p>
</div>
</li>
<li>
<p>Shutdown computer. Switch display cable so that it is connected to the secondary GPU. Start computer.</p>
</li>
<li>
<p>Validate that both GPUs are active and that the secondary GPU is used</p>
<div class="literalblock">
<div class="content">
<pre>```
$ nvidia-smi
Mon Jan  9 14:56:11 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 24%   41C    P0    17W / 250W |      1MiB / 12187MiB |      0%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 34%   44C    P8     3W /  30W |    129MiB /  2000MiB |      4%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    1      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+
```</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<h1 id="_acknowledgement" class="sect0">Acknowledgement</h1>
<div class="paragraph">
<p>This guide largely follows <a href="http://kislayabhi.github.io/Installing_CUDA_with_Ubuntu/">Installing CUDA with Ubuntu</a>, but has been updated for Ubuntu 16.04 and two GPUs.
<a href="https://github.com/ozanoktem">Ozan Öktem</a> helped compile the notes.</p>
</div>]]></description><link>https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</link><guid isPermaLink="true">https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</guid><dc:creator><![CDATA[Jonas Adler]]></dc:creator><pubDate>Wed, 19 Jul 2017 00:00:00 GMT</pubDate></item></channel></rss>