<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Jonas Adler]]></title><description><![CDATA[Ramblings on programming and mathematics]]></description><link>https://adler-j.github.io</link><generator>RSS for Node</generator><lastBuildDate>Thu, 20 Jul 2017 00:53:05 GMT</lastBuildDate><atom:link href="https://adler-j.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Dual GPU configuration in Ubuntu 16.04 and CUDA 8.0]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Instructions for installing and configuring Ubuntu 16.04 LTE on a PC with two GPUs.
The primary GPU will be used for computations and the secondary one will be used for displaying graphics.
In this example, the computer is a HP Z640 with NVIDIA Titan-X Pascal as primary GPU and a NVIDIA Quadro K620 as secondary GPU.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Turn off computer, ensure only the primary GPU is connected to the motherboard.
Boot from USB with Ubuntu 16.04 LTS installation,
install a fresh copy of Ubuntu 16.04 LTS but keep Windows partitions intact,
e.g. by choosing "Erase Ubuntu xx.yy and reinstall"</p>
</li>
<li>
<p>Install build essentials.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get install build-essential</pre>
</div>
</div>
</li>
<li>
<p>Go to <a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a> and download latest CUDA toolkit for Ubuntu 16.04 by selecting the following in the web-interface that is offered:</p>
<div class="ulist">
<ul>
<li>
<p>Operating system: Linux</p>
</li>
<li>
<p>Architecture: x86_64</p>
</li>
<li>
<p>Distribution: Ubuntu</p>
</li>
<li>
<p>Version: 16.04</p>
</li>
<li>
<p>Installer Type: runfile (local)</p>
<div class="paragraph">
<p>This will download the latest version,
which in the instructions will be is version 8.0.44,
so the file that will be downloaded is "cuda_8.0.44_linux.run"</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Open up a terminal and extract the separate installers via:</p>
<div class="literalblock">
<div class="content">
<pre>$ mkdir ~/Downloads/nvidia_installers
$ cd ~/Downloads
$ sudo chmod a+x ./cuda_8.0.44_linux.run
$ ./cuda_8.0.44_linux.run -extract=~/Downloads/nvidia_installers</pre>
</div>
</div>
</li>
<li>
<p>Completely uninstall anything in the ubuntu repositories with nvidia-*. I used synaptic and did a purge, AKA completely uninstall programs and configuration.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get --purge remove nvidia-*</pre>
</div>
</div>
</li>
<li>
<p>No need to create an xorg.conf file. If you have one, remove it (assuming you have a fresh OS install).</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo rm /etc/X11/xorg.conf</pre>
</div>
</div>
</li>
<li>
<p>Create the /etc/modprobe.d/blacklist-nouveau.conf file with the 2 following lines:</p>
<div class="literalblock">
<div class="content">
<pre>blacklist nouveau
options nouveau modeset=0</pre>
</div>
</div>
<div class="paragraph">
<p>Then do a</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo update-initramfs -u</pre>
</div>
</div>
</li>
<li>
<p>Reboot computer. Nothing should have changed in loading up menu.
You should be taken to the login screen.
Once there type: Ctrl + Alt + F1, and login to your user.
Keep the next commands handy in another machine since now you are in tty.</p>
</li>
<li>
<p>In tty:</p>
<div class="literalblock">
<div class="content">
<pre>cd ~/Downloads/nvidia_installers
sudo service lightdm stop</pre>
</div>
</div>
<div class="paragraph">
<p>The top line is a necessary step for installing the driver.</p>
</div>
</li>
<li>
<p>Now type</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./NVIDIA-Linux-x86_64-367.48.run --no-opengl-files</pre>
</div>
</div>
<div class="paragraph">
<p>The file "NVIDIA-Linux-x86_64-367.48.run" should have been created by the extract command at step (4.) above. It is important to include the opengl flag in the above command. If you miss that, either you will get stuck in ?login loop? or your computer would boot with a black screen at all times.</p>
</div>
<div class="paragraph">
<p>At some point you will get a warning message about 32-bit support, answer ok.</p>
</div>
<div class="paragraph">
<p>When prompted "The distribution-provided pre-installed script failed are you sure you want to continue". Answer continue.</p>
</div>
<div class="paragraph">
<p>If prompted to over-write xorg.conf, answer yes.</p>
</div>
<div class="paragraph">
<p>Pick defaults for all other options.</p>
</div>
</li>
<li>
<p>Now install the toolkit also</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./cuda-linux64-rel-8.0.44-21122537.run
sudo ./cuda-samples-linux-8.0.44-21122537.run</pre>
</div>
</div>
<div class="paragraph">
<p>Both the run-files above are suppose to have been created by the extract command at step (4.) above.</p>
</div>
<div class="paragraph">
<p>Pick defaults to all questions.</p>
</div>
<div class="paragraph">
<p>Pick yes for symbolic links.</p>
</div>
</li>
<li>
<p>Set Environment path variables in .bashrc:</p>
<div class="literalblock">
<div class="content">
<pre>export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</pre>
</div>
</div>
</li>
<li>
<p>Reload bash in order to apply these settings</p>
<div class="literalblock">
<div class="content">
<pre>$ exec bash</pre>
</div>
</div>
</li>
<li>
<p>Verify the driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module    367.48    Sat Sep    3 18:21:08 PDT 2016
GCC version:    gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1)</pre>
</div>
</div>
</li>
<li>
<p>Check CUDA driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44</pre>
</div>
</div>
</li>
<li>
<p>At this point you can switch the lightdm back on again by doing:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo service lightdm start</pre>
</div>
</div>
</li>
<li>
<p>Shut down computer, insert secondary GPU which in this example is a Quadro K620 card.</p>
</li>
<li>
<p>Boot computer, log in.</p>
</li>
<li>
<p>Check that both GPU cards are recognized by the system, by typing</p>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi
Mon Jan    9 14:47:10 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 34%   44C    P8    17W / 250W |    129MiB / 12187MiB |      4%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 24%   41C    P0     3W /  30W |      1MiB /  2000MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+</pre>
</div>
</div>
</li>
<li>
<p>Generate Nvidia X11 configuration file and activate multiple GPU option:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo nvidia-xconfig -multigpu=on</pre>
</div>
</div>
</li>
<li>
<p>Set the secondary GPU as the default GPU device for displaying graphics.</p>
<div class="paragraph">
<p>Find the PCI port of the secondary GPU by typing</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi -a</pre>
</div>
</div>
<div class="paragraph">
<p>In the output that follow, find the PCI bus related to the secondary GPU. Simply look for text in output where the "Product Name" matches the secondary GPU and read the PCI bus number.</p>
</div>
<div class="paragraph">
<p>In my current output is given below, the PCI bus is "3":</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[...]
GPU 0000:03:00.0
    Product Name                    : Quadro K620
    Product Brand                   : Quadro
    Display Mode                    : Enabled
    Display Active                  : Enabled
    Persistence Mode                : Disabled
    Accounting Mode                 : Disabled
    Accounting Mode Buffer Size     : 1920
    Driver Model
        Current                     : N/A
        Pending                     : N/A
    Serial Number                   : 0324114080422
    GPU UUID                        : GPU-4c631408-4129-9d5d-fbf3-0588bc1ab5cf
    Minor Number                    : 1
    VBIOS Version                   : 82.07.4E.00.0E
    MultiGPU Board                  : No
    Board ID                        : 0x300
    GPU Part Number                 : N/A
    Inforom Version
        Image Version               : 2012.0504.00.03
        OEM Object                  : 1.1
        ECC Object                  : N/A
        Power Management Object     : N/A
    GPU Operation Mode
        Current                     : N/A
        Pending                     : N/A
    GPU Virtualization Mode
        Virtualization mode         : None
    PCI
        Bus                         : 0x03
        Device                      : 0x00
        Domain                      : 0x0000
        Device Id                   : 0x13BB10DE
        Bus Id                      : 0000:03:00.0
[...]</pre>
</div>
</div>
<div class="paragraph">
<p>Update X11 configuration file.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo pico /etc/X11/xorg.conf</pre>
</div>
</div>
<div class="paragraph">
<p>Find the section</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>and replace with</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
    BusID          "PCI:3:0:0"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>Here, "3" should match the PCI bus as determined above.</p>
</div>
</li>
<li>
<p>Shutdown computer. Switch display cable so that it is connected to the secondary GPU. Start computer.</p>
</li>
<li>
<p>Validate that both GPUs are active and that the secondary GPU is used</p>
<div class="literalblock">
<div class="content">
<pre>```
$ nvidia-smi
Mon Jan  9 14:56:11 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 24%   41C    P0    17W / 250W |      1MiB / 12187MiB |      0%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 34%   44C    P8     3W /  30W |    129MiB /  2000MiB |      4%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    1      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+
```</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<h1 id="_acknowledgement" class="sect0">Acknowledgement</h1>
<div class="paragraph">
<p>This guide largely follows <a href="http://kislayabhi.github.io/Installing_CUDA_with_Ubuntu/">Installing CUDA with Ubuntu</a>, but has been updated for Ubuntu 16.04 and two GPUs.
<a href="https://github.com/ozanoktem">Ozan Ã–ktem</a> helped compile the notes.</p>
</div>]]></description><link>https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</link><guid isPermaLink="true">https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</guid><dc:creator><![CDATA[Jonas Adler]]></dc:creator><pubDate>Wed, 19 Jul 2017 00:00:00 GMT</pubDate></item></channel></rss>