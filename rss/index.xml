<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Jonas Adler]]></title><description><![CDATA[Ramblings on programming and mathematics]]></description><link>https://adler-j.github.io</link><generator>RSS for Node</generator><lastBuildDate>Thu, 27 Jul 2017 10:04:06 GMT</lastBuildDate><atom:link href="https://adler-j.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Learning to reconstruct]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Suppose that you were given a blurred image:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://adler-j.github.io/images/mayo_convolved.png" alt="mayo_convolved" width="300" height="300">
</div>
</div>
<div class="paragraph">
<p>Then you could probably tell that it was generated from this image:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_phantom.png" alt="mayo_phantom" width="300" height="300"></span></p>
</div>
<div class="paragraph">
<p>But what about if you instead were given <strong>indirect</strong> observations of the image, such as the line integrals taken over some set of lines:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_data.png" alt="mayo_data" width="300" height="300"></span></p>
</div>
<div class="paragraph">
<p>Would you still tell it came from the image above? Probably not. But we will demonstrate how we can teach a computer to do it.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These problems are called the deblurring and radon inversion problems respectively and are both examples of <em>inverse problems</em>. In inverse problem we seek to find (reconstruct) some parameter given indirect observations. Mathematically this can be stated as finding some parameter \(f\) that are connected to measured data \(g\) through a known <em>forward model</em> \(\mathcal{T}\):</p>
</div>
<div class="stemblock">
<div class="content">
\[g = \mathcal{T}(f) + noise\]
</div>
</div>
<div class="paragraph">
<p>Several classical image processing problems such as denoising, inpainting, deblurring and superresolution can be cast into this form, but it is also a good model for more complicated problems such as Magnetic Resonance Imaging (MRI) and Computed Tomography (CT).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_machine_learning_for_inverse_problems">Machine learning for inverse problems</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If the forward model is local, such as in deblurring where each datapoint is affected only by a small neighborhood of the image, finding the unknown parameter from data using machine learning is at least on a conceptual level straightforward. Simply use any standard convolutional neural network and known pairs \((g, f_{\text{true}})\) and train the neural network to map \(g\) to \(f_{\text{true}}\).</p>
</div>
<div class="paragraph">
<p>But what happens when \(\mathcal{T}\) is more complicated?
In Computed Tomography, the parameter \(f\) is an image of the interior of the patient and the forward model is given by the <a href="https://en.wikipedia.org/wiki/Radon_transform">Radon transform</a> which computes all line integrals of the image:</p>
</div>
<div class="stemblock">
<div class="content">
\[\mathcal{T}(f)(\ell) = \int_{\ell} f(x) dx  \quad \ell \text{ is a line in } \mathbb{R}^2\]
</div>
</div>
<div class="paragraph">
<p>If we compare this to the deblurring problem, we see that while the deblurring problem has a local relationship between parameter and data, the radon transform has a global relationship. Here two points on opposite sides of the image can still influence the same datapoint as long as they lie on the same line. And since the forward model is global, so is the inverse problem. This means that classical local machine-learning approaches based on convolutions will not work.</p>
</div>
<div class="paragraph">
<p>One way to solve this would be to use fully-connected layers instead of convolutions, but this quickly becomes infeasible. For example in the example above a single fully connected layer between data and signal would require a staggering \(2.6 \cdot 10^{11}\) weights. Storing these in single precision would require one terabyte of memory. For a single layer.</p>
</div>
<div class="paragraph">
<p>This is obviously not a workable solution.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_denoisers">Learned denoisers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>One of the most obvious solutions to this is to somehow recast the problem to an image-to-image problem. The most popular way of doing this is to first perform some initial (non machine-learning) reconstruction, e.g. <a href="https://en.wikipedia.org/wiki/Radon_transform#Radon_inversion_formula">Filtered Back-Projection</a> (FBP):</p>
</div>
<div class="videoblock">
<div class="content">
<video src="https://adler-j.github.io/images/mayo_fbp_animation.mp4" width="700" height="360" poster="https://adler-j.github.io/images/mayo_fbp_animation" autoplay controls loop>
Your browser does not support the video tag.
</video>
</div>
</div>
<div class="paragraph">
<p>Once this is done we can use any standard machine-learning approach to "denoise" the initial reconstruction by training a neural network to take the initial reconstruction as data and return the ground truth.</p>
</div>
<div class="paragraph">
<p>Several groups have done this and the results are in fact quite remarkable, <a href="http://bioeng.kaist.ac.kr/en/2016/09/01/bispl-were-the-1st-and-2nd-place-winners-of-the-ct-low-dose-grand-challenge/">outperforming previous state of the art methods</a>:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/learned_denoiser.png" alt="mayo_data" width="800" height="309"></span></p>
</div>
<div class="paragraph">
<p>However, the method leaves a sour taste. Sure the images certainly look better, but the only input was the initial reconstruction, so could it truly show anything that wasn&#8217;t already there?</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_primal_dual">Learned Primal-Dual</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This observation leads to a painful conclusion: in order to obtain a reconstruction with more information than current reconstruction methods, <strong>we need to work directly from raw data</strong>. But as we noted above, fully learning how to do this is practically impossible.</p>
</div>
<div class="paragraph">
<p>The solution is to take a middle way, to incorporate enough a-priori information  to make the problem tractable and then learn the rest.</p>
</div>
<div class="paragraph">
<p>The most powerful prior information we have is the forward operator \(\mathcal{T}\), but it only maps images to data. How would we go from data to images? One answer is to use the <a href="https://en.wikipedia.org/wiki/Hermitian_adjoint">adjoint operator</a> \(\mathcal{T}^*\).</p>
</div>
<div class="paragraph">
<p>The idea of our proposed solution (called the <em>Learned Primal-Dual</em> algorithm) is to use these operators alternatively. First we use a convolutional neural network to update the data (a so called <strong>dual</strong> step), then apply \(\mathcal{T}^*\) and use the result as input to another neural network which updates the reconstruction (the <strong>primal</strong> step), then apply \(\mathcal{T}\) and use it as input to a neural network that updates the data, and so on. This is iteratively performed a few times (10 in our experiments), at which point we have a final
reconstruction.</p>
</div>
<div class="paragraph">
<p>We train end-to-end with raw measured data as input and the reconstruction as output, without any initial reconstruction or other external information.</p>
</div>
<div class="paragraph">
<p>The good thing about this is that we separate the global aspect of the problem into the forward model and its adjoint and only need to learn the local aspects. The bad thing is that to train the network we need to perform back-propagation through this neural network that among others contain 10 calls to the forward operator, 10 calls the the adjoint operator and 20 small neural networks in between. We did this using some magic with Operator Discretization Library (<a href="https://github.com/odlgroup/odl">ODL</a>) and TensorFlow.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_results">Results</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you ask me, the results look quite good and I especially appreciate that the method is able to avoid some artifacts (some examples shown with red arrows) that the denoiser wasn&#8217;t able:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/compare_results_anotated.png" alt="compare_results_anotated" width="800" height="700"></span></p>
</div>
<div class="paragraph">
<p>The quantitative results are also quite good and we outperform learned denoising w.r.t both Peak Signal to Noise Ratio <a href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio">(PSNR)</a> and structural similarity index <a href="https://en.wikipedia.org/wiki/Structural_similarity">(SSIM)</a>. The runtime is not too shabby either and we manage to do all of this using only \(2\%\) of the trainable parameters used in the denoiser.</p>
</div>
<table class="tableblock frame-topbot grid-all spread">
<colgroup>
<col style="width: 31.25%;">
<col style="width: 18.75%;">
<col style="width: 12.5%;">
<col style="width: 18.75%;">
<col style="width: 18.75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">PSNR (dB)</th>
<th class="tableblock halign-left valign-top">SSIM</th>
<th class="tableblock halign-left valign-top">Runtime (ms)</th>
<th class="tableblock halign-left valign-top">Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FBP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">33.65</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.83</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>423</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>1</strong></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Denoiser</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">41.92</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.94</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">463</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(10^7\)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Proposed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>44.11</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>0.97</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">620</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(2.4 \cdot 10^5\)</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_read_more">Read more</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you found this interesting you should read our article "Learned Primal-Dual Reconstruction" on <a href="https://arxiv.org/abs/1707.06474">ArXiv</a> which describes the method in depth and gives a broader overview of what others have done in this exciting field. You could also have a look on the <a href="https://github.com/adler-j/learned_primal_dual">source code</a>.</p>
</div>
</div>
</div>]]></description><link>https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html</link><guid isPermaLink="true">https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html</guid><dc:creator><![CDATA[Jonas Adler]]></dc:creator><pubDate>Fri, 21 Jul 2017 00:00:00 GMT</pubDate></item><item><title><![CDATA[Dual GPU configuration in Ubuntu 16.04 and CUDA 8.0]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Instructions for installing and configuring Ubuntu 16.04 LTE on a PC with two GPUs.
The primary GPU will be used for computations and the secondary one will be used for displaying graphics.
In this example, the computer is a HP Z640 with NVIDIA Titan-X Pascal as primary GPU and a NVIDIA Quadro K620 as secondary GPU.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Turn off computer, ensure only the primary GPU is connected to the motherboard.
Boot from USB with Ubuntu 16.04 LTS installation,
install a fresh copy of Ubuntu 16.04 LTS but keep Windows partitions intact,
e.g. by choosing "Erase Ubuntu xx.yy and reinstall"</p>
</li>
<li>
<p>Install build essentials.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get install build-essential</pre>
</div>
</div>
</li>
<li>
<p>Go to <a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a> and download latest CUDA toolkit for Ubuntu 16.04 by selecting the following in the web-interface that is offered:</p>
<div class="ulist">
<ul>
<li>
<p>Operating system: Linux</p>
</li>
<li>
<p>Architecture: x86_64</p>
</li>
<li>
<p>Distribution: Ubuntu</p>
</li>
<li>
<p>Version: 16.04</p>
</li>
<li>
<p>Installer Type: runfile (local)</p>
<div class="paragraph">
<p>This will download the latest version,
which in the instructions will be is version 8.0.44,
so the file that will be downloaded is "cuda_8.0.44_linux.run"</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Open up a terminal and extract the separate installers via:</p>
<div class="literalblock">
<div class="content">
<pre>$ mkdir ~/Downloads/nvidia_installers
$ cd ~/Downloads
$ sudo chmod a+x ./cuda_8.0.44_linux.run
$ ./cuda_8.0.44_linux.run -extract=~/Downloads/nvidia_installers</pre>
</div>
</div>
</li>
<li>
<p>Completely uninstall anything in the ubuntu repositories with nvidia-*. I used synaptic and did a purge, AKA completely uninstall programs and configuration.</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo apt-get --purge remove nvidia-*</pre>
</div>
</div>
</li>
<li>
<p>No need to create an xorg.conf file. If you have one, remove it (assuming you have a fresh OS install).</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo rm /etc/X11/xorg.conf</pre>
</div>
</div>
</li>
<li>
<p>Create the /etc/modprobe.d/blacklist-nouveau.conf file with the 2 following lines:</p>
<div class="literalblock">
<div class="content">
<pre>blacklist nouveau
options nouveau modeset=0</pre>
</div>
</div>
<div class="paragraph">
<p>Then do a</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo update-initramfs -u</pre>
</div>
</div>
</li>
<li>
<p>Reboot computer. Nothing should have changed in loading up menu.
You should be taken to the login screen.
Once there type: Ctrl + Alt + F1, and login to your user.
Keep the next commands handy in another machine since now you are in tty.</p>
</li>
<li>
<p>In tty:</p>
<div class="literalblock">
<div class="content">
<pre>cd ~/Downloads/nvidia_installers
sudo service lightdm stop</pre>
</div>
</div>
<div class="paragraph">
<p>The top line is a necessary step for installing the driver.</p>
</div>
</li>
<li>
<p>Now type</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./NVIDIA-Linux-x86_64-367.48.run --no-opengl-files</pre>
</div>
</div>
<div class="paragraph">
<p>The file "NVIDIA-Linux-x86_64-367.48.run" should have been created by the extract command at step (4.) above. It is important to include the opengl flag in the above command. If you miss that, either you will get stuck in ?login loop? or your computer would boot with a black screen at all times.</p>
</div>
<div class="paragraph">
<p>At some point you will get a warning message about 32-bit support, answer ok.</p>
</div>
<div class="paragraph">
<p>When prompted "The distribution-provided pre-installed script failed are you sure you want to continue". Answer continue.</p>
</div>
<div class="paragraph">
<p>If prompted to over-write xorg.conf, answer yes.</p>
</div>
<div class="paragraph">
<p>Pick defaults for all other options.</p>
</div>
</li>
<li>
<p>Now install the toolkit also</p>
<div class="literalblock">
<div class="content">
<pre>sudo ./cuda-linux64-rel-8.0.44-21122537.run
sudo ./cuda-samples-linux-8.0.44-21122537.run</pre>
</div>
</div>
<div class="paragraph">
<p>Both the run-files above are suppose to have been created by the extract command at step (4.) above.</p>
</div>
<div class="paragraph">
<p>Pick defaults to all questions.</p>
</div>
<div class="paragraph">
<p>Pick yes for symbolic links.</p>
</div>
</li>
<li>
<p>Set Environment path variables in .bashrc:</p>
<div class="literalblock">
<div class="content">
<pre>export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</pre>
</div>
</div>
</li>
<li>
<p>Reload bash in order to apply these settings</p>
<div class="literalblock">
<div class="content">
<pre>$ exec bash</pre>
</div>
</div>
</li>
<li>
<p>Verify the driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module    367.48    Sat Sep    3 18:21:08 PDT 2016
GCC version:    gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.1)</pre>
</div>
</div>
</li>
<li>
<p>Check CUDA driver version:</p>
<div class="literalblock">
<div class="content">
<pre>$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44</pre>
</div>
</div>
</li>
<li>
<p>At this point you can switch the lightdm back on again by doing:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo service lightdm start</pre>
</div>
</div>
</li>
<li>
<p>Shut down computer, insert secondary GPU which in this example is a Quadro K620 card.</p>
</li>
<li>
<p>Boot computer, log in.</p>
</li>
<li>
<p>Check that both GPU cards are recognized by the system, by typing</p>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi
Mon Jan    9 14:47:10 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 34%   44C    P8    17W / 250W |    129MiB / 12187MiB |      4%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 24%   41C    P0     3W /  30W |      1MiB /  2000MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+</pre>
</div>
</div>
</li>
<li>
<p>Generate Nvidia X11 configuration file and activate multiple GPU option:</p>
<div class="literalblock">
<div class="content">
<pre>$ sudo nvidia-xconfig -multigpu=on</pre>
</div>
</div>
</li>
<li>
<p>Set the secondary GPU as the default GPU device for displaying graphics.</p>
<div class="paragraph">
<p>Find the PCI port of the secondary GPU by typing</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ nvidia-smi -a</pre>
</div>
</div>
<div class="paragraph">
<p>In the output that follow, find the PCI bus related to the secondary GPU. Simply look for text in output where the "Product Name" matches the secondary GPU and read the PCI bus number.</p>
</div>
<div class="paragraph">
<p>In my current output is given below, the PCI bus is "3":</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[...]
GPU 0000:03:00.0
    Product Name                    : Quadro K620
    Product Brand                   : Quadro
    Display Mode                    : Enabled
    Display Active                  : Enabled
    Persistence Mode                : Disabled
    Accounting Mode                 : Disabled
    Accounting Mode Buffer Size     : 1920
    Driver Model
        Current                     : N/A
        Pending                     : N/A
    Serial Number                   : 0324114080422
    GPU UUID                        : GPU-4c631408-4129-9d5d-fbf3-0588bc1ab5cf
    Minor Number                    : 1
    VBIOS Version                   : 82.07.4E.00.0E
    MultiGPU Board                  : No
    Board ID                        : 0x300
    GPU Part Number                 : N/A
    Inforom Version
        Image Version               : 2012.0504.00.03
        OEM Object                  : 1.1
        ECC Object                  : N/A
        Power Management Object     : N/A
    GPU Operation Mode
        Current                     : N/A
        Pending                     : N/A
    GPU Virtualization Mode
        Virtualization mode         : None
    PCI
        Bus                         : 0x03
        Device                      : 0x00
        Domain                      : 0x0000
        Device Id                   : 0x13BB10DE
        Bus Id                      : 0000:03:00.0
[...]</pre>
</div>
</div>
<div class="paragraph">
<p>Update X11 configuration file.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ sudo pico /etc/X11/xorg.conf</pre>
</div>
</div>
<div class="paragraph">
<p>Find the section</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>and replace with</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
    BusID          "PCI:3:0:0"
EndSection</pre>
</div>
</div>
<div class="paragraph">
<p>Here, "3" should match the PCI bus as determined above.</p>
</div>
</li>
<li>
<p>Shutdown computer. Switch display cable so that it is connected to the secondary GPU. Start computer.</p>
</li>
<li>
<p>Validate that both GPUs are active and that the secondary GPU is used</p>
<div class="literalblock">
<div class="content">
<pre>```
$ nvidia-smi
Mon Jan  9 14:56:11 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
| 24%   41C    P0    17W / 250W |      1MiB / 12187MiB |      0%      Default |
|-------------------------------+----------------------+----------------------+
|   1  Quadro K620         Off  | 0000:03:00.0      On |                  N/A |
| 34%   44C    P8     3W /  30W |    129MiB /  2000MiB |      4%      Default |
+-------------------------------+----------------------+----------------------+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    1      3954    G   /usr/lib/xorg/Xorg                             128MiB |
+-----------------------------------------------------------------------------+
```</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<h1 id="_acknowledgement" class="sect0">Acknowledgement</h1>
<div class="paragraph">
<p>This guide largely follows <a href="http://kislayabhi.github.io/Installing_CUDA_with_Ubuntu/">Installing CUDA with Ubuntu</a>, but has been updated for Ubuntu 16.04 and two GPUs.
<a href="https://github.com/ozanoktem">Ozan Öktem</a> helped compile the notes.</p>
</div>]]></description><link>https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</link><guid isPermaLink="true">https://adler-j.github.io/2017/07/19/Dual-GPU-configuration-in-Ubuntu-1604-and-CUDA-80.html</guid><dc:creator><![CDATA[Jonas Adler]]></dc:creator><pubDate>Wed, 19 Jul 2017 00:00:00 GMT</pubDate></item></channel></rss>