<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Learning to reconstruct</title>
    <meta name="description" content="" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="https://adler-j.github.io/favicon.ico">

    <link rel="stylesheet" type="text/css" href="//adler-j.github.io/themes/casper/assets/css/screen.css?v=1500666515356" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />

    <link rel="canonical" href="https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html" />
    <meta name="referrer" content="origin" />
    
    <meta property="og:site_name" content="Jonas Adler" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Learning to reconstruct" />
    <meta property="og:description" content="Suppose that you were given a smoothed image: Then you could probably tell that it was generated from this image: But what about if I instead gave you the line integrals of the image: Would you still tell it came from the image above? Probably not. But we will demonstrate" />
    <meta property="og:url" content="https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html" />
    <meta property="article:published_time" content="2017-07-21T00:00:00.000Z" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Learning to reconstruct" />
    <meta name="twitter:description" content="Suppose that you were given a smoothed image: Then you could probably tell that it was generated from this image: But what about if I instead gave you the line integrals of the image: Would you still tell it came from the image above? Probably not. But we will demonstrate" />
    <meta name="twitter:url" content="https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html" />
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Jonas Adler",
    "author": {
        "@type": "Person",
        "name": "Jonas Adler",
        "image": "https://avatars2.githubusercontent.com/u/2202312?v=4",
        "url": "https://adler-j.github.io/author/adler-j/",
        "sameAs": "https://adler-j.github.io",
        "description": "Industrial PhD student in applied mathematics at KTH, working for Elekta."
    },
    "headline": "Learning to reconstruct",
    "url": "https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html",
    "datePublished": "2017-07-21T00:00:00.000Z",
    "description": "Suppose that you were given a smoothed image: Then you could probably tell that it was generated from this image: But what about if I instead gave you the line integrals of the image: Would you still tell it came from the image above? Probably not. But we will demonstrate"
}
    </script>

    <meta name="generator" content="HubPress" />
    <link rel="alternate" type="application/rss+xml" title="Jonas Adler" href="https://adler-j.github.io/rss/" />
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.10.0/styles/atom-one-dark.min.css">
</head>
<body class="post-template nav-closed">

    

    <div class="site-wrapper">

        


<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        
    </nav>
</header>

<main class="content" role="main">
    <article class="post">

        <header class="post-header">
            <h1 class="post-title">Learning to reconstruct</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2017-07-21">21 July 2017</time> 
            </section>
        </header>

        <section class="post-content">
            <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Suppose that you were given a smoothed image:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://adler-j.github.io/images/mayo_convolved.png" alt="mayo_convolved" width="400" height="400">
</div>
</div>
<div class="paragraph">
<p>Then you could probably tell that it was generated from this image:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_phantom.png" alt="mayo_phantom" width="400" height="400"></span></p>
</div>
<div class="paragraph">
<p>But what about if I instead gave you the line integrals of the image:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/mayo_data.png" alt="mayo_data" width="400" height="400"></span></p>
</div>
<div class="paragraph">
<p>Would you still tell it came from the image above? Probably not. But we will demonstrate how we can teach a computer to do it.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_an_introduction_to_inverse_problems">An introduction to inverse problems</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In inverse problems we seeks to find (reconstruct) some parameters given indirect observations. Mathematically this can be stated as finding some parameters \(f\) that is connected to our measured data \(g\) through the <em>forward model</em> \(\mathcal{T}\):</p>
</div>
<div class="stemblock">
<div class="content">
\[g = \mathcal{T}(f) + noise\]
</div>
</div>
<div class="paragraph">
<p>Several classical image processing problems can be cast into this form, including denoising, inpainting, deconvolution and superresolution. But it is also a good model for more complicated modalities such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI), etc.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_machine_learning_for_inverse_problems">Machine learning for inverse problems</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If \(\mathcal{T}\) maps images to images, such as the convolution above, finding \(f\) from \(g\) using machine learning is at least on a conceptual level trivial, and any architecture such as Denoising Autoencoders, Generative Advesarial Networks, etc could be used to learn a transformation from \(g\) to \(f\).</p>
</div>
<div class="paragraph">
<p>But what happens when \(\mathcal{T}\) is more complicated?
We&#8217;ll focus on CT, where the forward model is given by the <a href="https://en.wikipedia.org/wiki/Radon_transform">Radon transform</a></p>
</div>
<div class="stemblock">
<div class="content">
\[\mathcal{T}(f)(\ell) = \int_{\ell} f(x) dx  \quad \ell \text{ is a line in } \mathbb{R}^2\]
</div>
</div>
<div class="paragraph">
<p>The main complication here is that we have a global relationship between signal and data, where two widely separated points in an image can both influence a point in data. And since the forward model is global, so is the inverse problem. This means that classical machine-learning approaches based on convolutions will not work.</p>
</div>
<div class="paragraph">
<p>One way to solve this would be to use fully-connected layers instead of convolutions, but this quickly becomes infeasible. For example, in the example above the data has size \(1000 \times 1000 = 10^6\), and the signal \(512 \times 512 = 2.6 \cdot 10^5\). A single fully connected layer between these would require a staggering \(10^6 \cdot 2.6 \cdot 10^5 = 2.6 \cdot 10^{11}\) weights. Storing these in single precision would require one terrabyte of data. For a single layer.</p>
</div>
<div class="paragraph">
<p>This is obviously not a workable solution.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_denoisers">Learned denoisers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>One of the most obvious solutions to this problem is to somehow re-cast the problem back into a image-to-image problem. The most popular way of doing this is to first apply some initial reconstruction, e.g. <a href="https://en.wikipedia.org/wiki/Radon_transform#Radon_inversion_formula">Filtered Back-Projection</a> (FBP):</p>
</div>
<div class="videoblock">
<div class="content">
<video src="https://adler-j.github.io/images/mayo_fbp_animation.mp4" width="800" height="309" poster="https://adler-j.github.io/images/mayo_fbp_animation" controls>
Your browser does not support the video tag.
</video>
</div>
</div>
<div class="paragraph">
<p>Once this has been applied, we can use any standard machine-learning approach to "denoise" the result by training a neural network to take low quality images as input and return high quality images.</p>
</div>
<div class="paragraph">
<p>Several people have done this and the results are in fact quite remarkable:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="https://adler-j.github.io/images/learned_denoiser.png" alt="mayo_data" width="800" height="309"></span></p>
</div>
<div class="paragraph">
<p>However, these methods leave a sour after-taste. Sure the images look better, but the only input they had was the low quality image. Hence they cannot possibly show something that was not present in the low quality image. So is the denoised image truly better?</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learned_primal_dual">Learned Primal-Dual</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This observation leads us to a painful conclusion: in order to get a reconstruction that contains more information than current reconstructions, we <em>need</em> to work directly from raw data. But as we noted above, learning how to do this is practually impossible.</p>
</div>
<div class="paragraph">
<p>A solution is to</p>
</div>
</div>
</div>
        </section>

        <footer class="post-footer">


            <figure class="author-image">
                <a class="img" href="https://adler-j.github.io/author/adler-j/" style="background-image: url(https://avatars2.githubusercontent.com/u/2202312?v&#x3D;4)"><span class="hidden">Jonas Adler's Picture</span></a>
            </figure>

            <section class="author">
                <h4><a href="https://adler-j.github.io/author/adler-j/">Jonas Adler</a></h4>

                    <p>Industrial PhD student in applied mathematics at KTH, working for Elekta.</p>
                <div class="author-meta">
                    <span class="author-location icon-location">Stockholm, Sweden</span>
                    <span class="author-link icon-link"><a href="https://adler-j.github.io">https://adler-j.github.io</a></span>
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/intent/tweet?text=Learning%20to%20reconstruct&amp;url=https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html"
                    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html"
                    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=https://adler-j.github.io/2017/07/21/Learning-to-reconstruct.html"
                   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

        </footer>


    </article>

</main>

<aside class="read-next">
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="https://adler-j.github.io">Jonas Adler</a> &copy; 2017</section>
            <section class="poweredby">Proudly published with <a href="http://hubpress.io">HubPress</a></section>
        </footer>

    </div>

    <script type="text/javascript" src="https://code.jquery.com/jquery-1.12.0.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.9.0/moment-with-locales.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.10.0/highlight.min.js?v="></script> 
      <script type="text/javascript">
        jQuery( document ).ready(function() {
          // change date with ago
          jQuery('ago.ago').each(function(){
            var element = jQuery(this).parent();
            element.html( moment(element.text()).fromNow());
          });
        });

        hljs.initHighlightingOnLoad();
      </script>
       
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

    <script type="text/javascript" src="//adler-j.github.io/themes/casper/assets/js/jquery.fitvids.js?v=1500666515356"></script>
    <script type="text/javascript" src="//adler-j.github.io/themes/casper/assets/js/index.js?v=1500666515356"></script>

</body>
</html>
